{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kaitlynlaii/NUS_DATATHON_SINGLIFE_NUS_124/blob/main/test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The cell below is for you to keep track of the libraries used and install those libraries quickly\n",
        "\n",
        "Ensure that the proper library names are used and the syntax of %pip install PACKAGE_NAME is followed\n",
        "\n"
      ],
      "metadata": {
        "id": "T7VISUk85s6E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#%pip install pandas\n",
        "#%pip install matplotlib\n",
        "# add commented pip installation lines for packages used as shown above for ease of testing\n",
        "# the line should be of the format %pip install PACKAGE_NAME"
      ],
      "metadata": {
        "id": "OPGDGj2R5w8f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "DO NOT CHANGE the filepath variable\n",
        "\n",
        "Instead, create a folder named 'data' in your current working directory and\n",
        "\n",
        "have the .parquet file inside that. A relative path must be used when loading data into pandas"
      ],
      "metadata": {
        "id": "3jH9vI1J5yUE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Can have as many cells as you want for code\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "filepath = \"./data/catB_train.parquet\"\n",
        "# the initialised filepath MUST be a relative path to a folder named data that contains the parquet file"
      ],
      "metadata": {
        "id": "uu0N0G7t50tY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ALL Code for machine learning and dataset analysis should be entered below.\n",
        "\n",
        "Ensure that your code is clear and readable.\n",
        "\n",
        "Comments and Markdown notes are advised to direct attention to pieces of code you deem useful.\n",
        "In [ ]:\n"
      ],
      "metadata": {
        "id": "W-b94DDN50N2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_parquet(filepath)"
      ],
      "metadata": {
        "id": "fNk_wE2b549N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The cell below is NOT to be removed\n",
        "\n",
        "The function is to be amended so that it accepts the given input (dataframe) and returns the required output (list).\n",
        "\n",
        "It is recommended to test the function out prior to submission\n",
        "\n",
        "The hidden_data parsed into the function below will have the same layout columns wise as the dataset SENT to you\n",
        "\n",
        "Thus, ensure that steps taken to modify the initial dataset to fit into the model are also carried out in the function below\n",
        "In [ ]:\n"
      ],
      "metadata": {
        "id": "5TjNVgUy6AJK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def testing_hidden_data(hidden_data: pd.DataFrame) -> list:\n",
        "    '''DO NOT REMOVE THIS FUNCTION.\n",
        "\n",
        "The function accepts a dataframe as input and return an iterable (list)\n",
        "of binary classes as output.\n",
        "\n",
        "The function should be coded to test on hidden data\n",
        "and should include any preprocessing functions needed for your model to perform.\n",
        "\n",
        "All relevant code MUST be included in this function.'''\n",
        "    df = hidden_data\n",
        "    # Convert target col to 0 or 1\n",
        "    df[\"f_purchase_lh\"] = df[\"f_purchase_lh\"].fillna(0)\n",
        "    # Set the threshold for missing values (50%)\n",
        "    threshold = 0.5 * len(df)\n",
        "\n",
        "    # Drop columns with 50% or more missing values\n",
        "    df = df.dropna(axis=1, thresh=threshold)\n",
        "\n",
        "    # Drop clntnum, ctrycode and date columns\n",
        "    df = df.drop(columns=['clntnum', 'min_occ_date', 'cltdob_fix', 'ctrycode_desc'])\n",
        "    df_columns_obj = df.select_dtypes(include='object').columns.tolist()\n",
        "\n",
        "    # fill missing obj values with mode\n",
        "    for title in df_columns_obj:\n",
        "      df[title] = df[title].fillna(df[title].mode()[0])\n",
        "\n",
        "    ### Manually change the object datatypes to integers / floats types\n",
        "    # all ape/sumins/prempaid > float\n",
        "    to_float = [col for col in df.columns if 'ape' in col or 'sumins' in col or 'prempaid' in col]\n",
        "    df[to_float] = df[to_float].astype(float)\n",
        "\n",
        "    # all n_months, hh_20, pop_20 > int\n",
        "    to_int = [col for col in df.columns if 'n_months' in col]\n",
        "    to_int.extend(['hh_20','pop_20'])\n",
        "    df[to_int] = df[to_int].astype('int64')\n",
        "\n",
        "    # race, clnt type, stat, sex > nominal, one hot encoding\n",
        "    to_one_hot = ['race_desc', 'clttype', 'stat_flag', 'cltsex_fix']\n",
        "    df = pd.get_dummies(df, columns=to_one_hot)\n",
        "\n",
        "    # hh_size, annual income > ordinal encoding\n",
        "    from sklearn.preprocessing import OrdinalEncoder\n",
        "    to_ordinal = ['hh_size_est', 'annual_income_est']\n",
        "    categories = [['0','1', '2', '3', '4', '>4'], ['E.BELOW30K','D.30K-60K','C.60K-100K' ,'B.100K-200K','A.ABOVE200K']]\n",
        "    encoder = OrdinalEncoder(categories=categories)\n",
        "    df[to_ordinal] = encoder.fit_transform(df[to_ordinal])\n",
        "\n",
        "    numeric_cols = df.select_dtypes(include=[\"int64\", \"float64\"]).columns\n",
        "    df[numeric_cols] = df[numeric_cols].apply(lambda x: x.fillna(x.median()))\n",
        "\n",
        "    y = df[\"f_purchase_lh\"]\n",
        "    X = df.drop(columns=['f_purchase_lh'])\n",
        "\n",
        "    from sklearn.preprocessing import StandardScaler\n",
        "    scaler = StandardScaler()\n",
        "    df[df.columns] = scaler.fit_transform(df[df.columns])\n",
        "\n",
        "    from sklearn.model_selection import train_test_split\n",
        "    from collections import Counter\n",
        "\n",
        "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "\n",
        "    selected = [\"n_months_last_bought_gi\",\n",
        "                  \"is_valid_email\",\n",
        "                  \"n_months_last_bought_products\",\n",
        "                  \"f_ever_bought_gi\",\n",
        "                  \"is_valid_dm\",\n",
        "                  \"f_mindef_mha\",\n",
        "                  \"f_retail\",\n",
        "                  \"hh_size\",\n",
        "                  \"pop_20\" ]\n",
        "    X_train = X_train[selected]\n",
        "    X_val = X_val[selected]\n",
        "\n",
        "    from collections import Counter\n",
        "    from imblearn.over_sampling import SMOTE\n",
        "    # SMOTE on training set only\n",
        "    X_train, y_train = SMOTE().fit_resample(X_train, y_train)\n",
        "\n",
        "    from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "    from sklearn.ensemble import RandomForestClassifier\n",
        "    rf_model = RandomForestClassifier(random_state=42)\n",
        "    rf_model.fit(X_train, y_train)\n",
        "\n",
        "    y_pred_rf = rf_model.predict(X_val)\n",
        "\n",
        "    # Evaluate the Random Forest model\n",
        "    accuracy_rf = accuracy_score(y_val, y_pred_rf)\n",
        "    conf_matrix_rf = confusion_matrix(y_val, y_pred_rf)\n",
        "    classification_rep_rf = classification_report(y_val, y_pred_rf)\n",
        "\n",
        "    result = [classification_rep_rf]\n",
        "    return result"
      ],
      "metadata": {
        "id": "jvBNBiQn6B-o"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}